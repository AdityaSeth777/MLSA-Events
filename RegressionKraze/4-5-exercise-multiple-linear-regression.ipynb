{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "55900efb-681d-40e9-83c7-b5c38bd6b2ab",
      "metadata": {},
      "source": [
        "# Exercise: Train a multiple linear regression model\n",
        "In this exercise, we'll train both a simple linear-regression model and a multiple linear-regression model and compare their performance using R-Squared.\n",
        "\n",
        "## Loading data\n",
        "Let's start by having a look at our data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7581d6f-b01b-4168-975f-c4dfa2799b00",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas\n",
        "import urllib.request\n",
        "import os\n",
        "\n",
        "# Install necessary packages\n",
        "!pip install statsmodels\n",
        "!pip install plotly\n",
        "\n",
        "# Download necessary files\n",
        "data_url = \"https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/doggy-illness.csv\"\n",
        "graphing_url = \"https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/graphing.py\"\n",
        "\n",
        "urllib.request.urlretrieve(data_url, \"doggy-illness.csv\")\n",
        "urllib.request.urlretrieve(graphing_url, \"graphing.py\")\n",
        "\n",
        "# Convert it into a table using pandas\n",
        "dataset = pandas.read_csv(\"doggy-illness.csv\", delimiter=\"\\t\")\n",
        "\n",
        "# Print the data\n",
        "print(dataset)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "455073bd-1295-4152-b2d4-d832c58d47ef",
      "metadata": {},
      "source": [
        "For this exercise, we'll try to predict `core_temperature` from some of the other available features. \n",
        "\n",
        "## Data visualization\n",
        "\n",
        "Let's quickly eyeball which features seem to have some kind of relationship with `core_temperature`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b56cedf-de91-43ca-b44a-f1c254c96fea",
      "metadata": {},
      "outputs": [],
      "source": [
        "import graphing # Custom graphing code that uses Plotly. See our GitHub repository for details\n",
        "\n",
        "graphing.box_and_whisker(dataset, \"male\", \"core_temperature\", show=True)\n",
        "graphing.box_and_whisker(dataset, \"attended_training\", \"core_temperature\", show=True)\n",
        "graphing.box_and_whisker(dataset, \"ate_at_tonys_steakhouse\", \"core_temperature\", show=True)\n",
        "graphing.scatter_2D(dataset, \"body_fat_percentage\", \"core_temperature\", show=True)\n",
        "graphing.scatter_2D(dataset, \"protein_content_of_last_meal\", \"core_temperature\", show=True)\n",
        "graphing.scatter_2D(dataset, \"age\", \"core_temperature\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b3a16e9-e6dc-4835-85b8-1592b9ef9911",
      "metadata": {},
      "source": [
        "At a glance, fatter, older, and male dogs seem to more commonly have higher temperatures than thinner, younger, or female dogs. Dogs who ate a lot of protein last night also seem to be more unwell. The other features don't seem particularly useful.\n",
        "\n",
        "## Simple linear regression\n",
        "\n",
        "Let's try to predict `core_temperature` using simple linear regression, and note the R-Squared for these relationships."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f2d0240-657b-444e-a0d4-ba30bbb02125",
      "metadata": {},
      "outputs": [],
      "source": [
        "import statsmodels.formula.api as smf\n",
        "import graphing # custom graphing code. See our GitHub repo for details\n",
        "\n",
        "for feature in [\"male\", \"age\", \"protein_content_of_last_meal\", \"body_fat_percentage\"]:\n",
        "    # Perform linear regression. This method takes care of\n",
        "    # the entire fitting procedure for us.\n",
        "    formula = \"core_temperature ~ \" + feature\n",
        "    simple_model = smf.ols(formula = formula, data = dataset).fit()\n",
        "\n",
        "    print(feature)\n",
        "    print(\"R-squared:\", simple_model.rsquared)\n",
        "    \n",
        "    # Show a graph of the result\n",
        "    graphing.scatter_2D(dataset, label_x=feature, \n",
        "                                 label_y=\"core_temperature\",\n",
        "                                 title = feature,\n",
        "                                 trendline=lambda x: simple_model.params[1] * x + simple_model.params[0],\n",
        "                                 show=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "343d32e8-aaaa-4cc1-bbb4-ac568271fd2d",
      "metadata": {},
      "source": [
        "Scrolling through these graphs, we get R-square values of 0.0002 (`body_fat_percentage`), 0.1 (`male`), and 0.26 (`age`).\n",
        "\n",
        "While `protein_content_of_last_meal` looks very promising too, the relationship looks curved, not linear. We'll leave this feature for now and come back to it in the next exercise."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "65464b41-5f7f-45c2-8938-71dbe70a4c89",
      "metadata": {},
      "source": [
        "## R-Squared\n",
        "\n",
        "We've shown the R-Squared value for these models and used it as a measure of \"correctness\" for our regression, but what is it?\n",
        "\n",
        "Intuitively, we can think of R-Squared as ratio for how much better our regression line is than a naive regression that just goes straight through the mean of all examples. \n",
        "\n",
        "Roughly, the R-Squared is calculated by taking the loss/error of the trained model, and dividing by the loss/error of the naive model. That gives a range where `0` is better and `1` is worse, so the whole thing is subtracted from `1` to flip those results.\n",
        "\n",
        "In the following code, we once again show the scatter plot with `age` and `core_temperature`, but this time, we show two regression lines. The first is the naive line that just goes straight through the mean. This has an R-Squared of `0` (since it's no better than itself). An R-Squared of `1` would be a line that fit each training example perfectly. The second plot shows our trained regression line, and we once again see its R-Squared."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc9d508e-95a0-42ec-b002-4570b7b90d01",
      "metadata": {},
      "outputs": [],
      "source": [
        "formula = \"core_temperature ~ age\"\n",
        "age_trained_model = smf.ols(formula = formula, data = dataset).fit()\n",
        "age_naive_model = smf.ols(formula = formula, data = dataset).fit()\n",
        "age_naive_model.params[0] = dataset['core_temperature'].mean()\n",
        "age_naive_model.params[1] = 0\n",
        "\n",
        "print(\"naive R-squared:\", age_naive_model.rsquared)\n",
        "print(\"trained R-squared:\", age_trained_model.rsquared)\n",
        "\n",
        "# Show a graph of the result\n",
        "graphing.scatter_2D(dataset, label_x=\"age\", \n",
        "                                label_y=\"core_temperature\",\n",
        "                                title = \"Naive model\",\n",
        "                                trendline=lambda x: dataset['core_temperature'].repeat(len(x)), \n",
        "                                show=True)\n",
        "# Show a graph of the result\n",
        "graphing.scatter_2D(dataset, label_x=\"age\", \n",
        "                                label_y=\"core_temperature\",\n",
        "                                title = \"Trained model\",\n",
        "                                trendline=lambda x: age_trained_model.params[1] * x + age_trained_model.params[0])\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "5e57f5c5-74a6-4c5c-b7a3-00f37ba7de77",
      "metadata": {},
      "source": [
        "## Multiple Linear Regression\n",
        "\n",
        "Instead of modeling these separately, lets try to combine these into a single model. Body fat didn't seem to be useful after all, so let's just use `male` and `age` as features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c67c62f9-1fe7-445f-b5f7-19a5eda93751",
      "metadata": {},
      "outputs": [],
      "source": [
        "model = smf.ols(formula = \"core_temperature ~ age + male\", data = dataset).fit()\n",
        "\n",
        "print(\"R-squared:\", model.rsquared)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "8a2d841b-f655-4bcd-b840-26b2ca859c6c",
      "metadata": {},
      "source": [
        "By using both features at the same time, we got a better result than any of the one-feature (univariate) models.\n",
        "\n",
        "How can we view this, though? Well, a simple linear regression is drawn in 2D. If we're working with an extra variable, we add one dimension and work in 3D. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd797343-c398-43a1-9f5e-6e1a96a8ff83",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# Show a graph of the result\n",
        "# this needs to be 3D, because we now have three variables in play: two features and one label\n",
        "\n",
        "def predict(age, male):\n",
        "    '''\n",
        "    This converts given age and male values into a prediction from the model\n",
        "    '''\n",
        "    # to make a prediction with statsmodels, we need to provide a dataframe\n",
        "    # so create a dataframe with just the age and male variables\n",
        "    df = pandas.DataFrame(dict(age=[age], male=[male]))\n",
        "    return model.predict(df)\n",
        "\n",
        "# Create the surface graph\n",
        "fig = graphing.surface(\n",
        "    x_values=np.array([min(dataset.age), max(dataset.age)]),\n",
        "    y_values=np.array([0, 1]),\n",
        "    calc_z=predict,\n",
        "    axis_title_x=\"Age\",\n",
        "    axis_title_y=\"Male\",\n",
        "    axis_title_z=\"Core temperature\"\n",
        ")\n",
        "\n",
        "# Add our datapoints to it and display\n",
        "fig.add_scatter3d(x=dataset.age, y=dataset.male, z=dataset.core_temperature, mode='markers')\n",
        "fig.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "e16f5e2b-e613-4a28-a504-0f154ad3c15f",
      "metadata": {},
      "source": [
        "The preceding graph above interactive. Try rotating it to see how the model (shown as a solid plane) would predict core temperature from different combinations of age and sex.\n",
        "\n",
        "### Inspecting our model\n",
        "\n",
        "When we have more than two features, it becomes very difficult to visualize these models. We usually have to look at the parameters directly. Let's do that now. _Statsmodels_, one of the common machine learning and statistics libraries, provides a `summary()` method that provides information about our model.    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f66bc86-fc4e-45e0-868f-552a79a33f18",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print summary information\n",
        "model.summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "3798e892-0053-4262-8e60-859a57d214e5",
      "metadata": {},
      "source": [
        "If we look at the top right-hand corner, we can see our R-squared statistic that we printed out earlier.\n",
        "\n",
        "Slightly down and to the left, we can also see information about the data we trained our model on. For example, we can see that we trained it on 98 observations (`No. Observations`).\n",
        "\n",
        "Under this, we find information about our parameters in a column called `coef` (which stands for _coefficients_, a synonym for parameters in machine learning). Here, we can see the intercept was about `38`, meaning that the model predicts a core temperature of 38 for a dog with `age=0` and `male=0`. Underneath this, we see the parameter for age is 0.14, meaning that for each additional year of age, the predicted temperature would rise 0.14 degrees celsius. For `male`, we can see a parameter of 0.32, meaning that the model estimates all dogs (that is, where `male == 1`) to have temperatures 0.32 degrees celsius higher than female dogs (where `male == 0`).\n",
        "\n",
        "Although we don't have space here to go into detail, the `P` column is also very useful. This tells us how confident the model is about this parameter value. As a rule of thumb, if the *p-value* is less than 0.05, there is a good chance that this relationship if trustable. For example, here both `age` and `male` are less than 0.05, so we should feel confident using this model in the real world.\n",
        "\n",
        "As a final exercise, let's do the same thing with our earlier simple linear-regression model, relating `age` to `core_temperature`. Read through the following table and see what you can make out from this model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a095471-26dc-4ad2-8575-5537a03ef182",
      "metadata": {},
      "outputs": [],
      "source": [
        "age_trained_model.summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "0ba8d6f5-ac6c-48cc-ba38-bc13838166a5",
      "metadata": {},
      "source": [
        "## Summary\n",
        "We covered the following concepts in this exercise:\n",
        "\n",
        "- Built simple and multiple linear-regression models.\n",
        "- Compared the performance of both models by looking at R-Squared values.\n",
        "- Inspected models to understand how they work."
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "conda-env-azureml_py38-py"
    },
    "kernelspec": {
      "display_name": "py38_default",
      "language": "python",
      "name": "conda-env-azureml_py38-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "2a35a5d7a1695c145f6d485f5528d9f0e062df43578e4fcb0dcb8fc15dd48b38"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
